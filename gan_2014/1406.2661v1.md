Generative Adversarial Networks

# Redes Generativas Adversariales

## Resumen

Proponemos un nuevo marco para la estimación de modelos generativos mediante un proceso adversarial, en el que simultáneamente entrenamos dos modelos: uno generativo y uno discriminativo. El modelo generativo captura la distribución de los datos, mientras que el modelo discriminativo estima la probabilidad de que una muestra provenga de los datos de entrenamiento en lugar del modelo generativo. El proceso de entrenamiento de este marco corresponde a un juego minimax de dos jugadores. Los experimentos demuestran que este procedimiento es capaz de generar imágenes de manera plausible y que puede aprender características generativas profundas en diversas aplicaciones.

---

Este abstract describe la propuesta y el objetivo principal del paper, proporcionando una visión general del enfoque novedoso de las Redes Generativas Adversariales y sus resultados experimentales.

## 1 Introducción

La promesa del aprendizaje profundo es descubrir modelos ricos y jerárquicos [2] que representen distribuciones de probabilidad sobre los tipos de datos encontrados en aplicaciones de inteligencia artificial, tales como imágenes naturales, formas de onda de audio que contienen habla y símbolos en corpus de lenguaje natural. Hasta ahora, los éxitos más notables en el aprendizaje profundo han involucrado modelos discriminativos, generalmente aquellos que mapean una entrada sensorial rica y de alta dimensión a una etiqueta de clase [14, 22]. Estos éxitos notables se han basado principalmente en los algoritmos de retropropagación y dropout, utilizando unidades lineales por partes [19, 9, 10] que tienen un gradiente particularmente bien comportado. Los modelos generativos profundos han tenido menos impacto debido a la dificultad de aproximar muchos cálculos probabilísticos intratables que surgen en la estimación de máxima verosimilitud y estrategias relacionadas, y debido a la dificultad de aprovechar los beneficios de las unidades lineales por partes en el contexto generativo. Proponemos un nuevo procedimiento de estimación de modelos generativos que evita estas dificultades.

En el marco de redes adversariales propuesto, el modelo generativo se enfrenta a un adversario: un modelo discriminativo que aprende a determinar si una muestra proviene de la distribución del modelo o de la distribución de los datos. El modelo generativo puede considerarse análogo a un equipo de falsificadores, tratando de producir moneda falsa y usarla sin ser detectados, mientras que el modelo discriminativo es análogo a la policía, tratando de detectar la moneda falsa. La competencia en este juego impulsa a ambos equipos a mejorar sus métodos hasta que los falsificaciones sean indistinguibles de los artículos genuinos.

Este marco puede generar algoritmos de entrenamiento específicos para muchos tipos de modelos y algoritmos de optimización. En este artículo, exploramos el caso especial cuando el modelo generativo genera muestras pasando ruido aleatorio a través de un perceptrón multicapa, y el modelo discriminativo también es un perceptrón multicapa. Nos referimos a este caso especial como redes adversariales. En este caso, podemos entrenar ambos modelos utilizando solo los algoritmos de retropropagación y dropout [17] y muestrear del modelo generativo utilizando solo la propagación hacia adelante. No es necesaria la inferencia aproximada ni las cadenas de Markov.

## 2 Trabajo Relacionado

Una alternativa a los modelos gráficos dirigidos con variables latentes son los modelos gráficos no dirigidos con variables latentes, como las máquinas de Boltzmann restringidas (RBMs) [27, 16], las máquinas de Boltzmann profundas (DBMs) [26] y sus numerosas variantes. Las interacciones dentro de estos modelos se representan como el producto de funciones potenciales no normalizadas, normalizadas mediante una suma/integración global sobre todos los estados de las variables aleatorias. Esta cantidad (la función de partición) y su gradiente son intratables para todos los casos salvo los más triviales, aunque pueden estimarse mediante métodos de Monte Carlo de cadena de Markov (MCMC). La mezcla plantea un problema significativo para los algoritmos de aprendizaje que dependen de MCMC [3, 5].

Las redes de creencias profundas (DBNs) [16] son modelos híbridos que contienen una capa no dirigida y varias capas dirigidas. Aunque existe un criterio de entrenamiento rápido y aproximado por capas, las DBNs incurren en las dificultades computacionales asociadas con los modelos tanto dirigidos como no dirigidos.

También se han propuesto criterios alternativos que no aproximan ni limitan la verosimilitud logarítmica, como el emparejamiento de puntuaciones (score matching) [18] y la estimación de contraste de ruido (NCE) [13]. Ambos requieren que la densidad de probabilidad aprendida se especifique analíticamente hasta una constante de normalización. Cabe señalar que en muchos modelos generativos interesantes con varias capas de variables latentes (como las DBNs y las DBMs), ni siquiera es posible derivar una densidad de probabilidad no normalizada tratable. Algunos modelos, como los autoencoders de denoising [30] y los autoencoders contractivos, tienen reglas de aprendizaje muy similares al emparejamiento de puntuaciones aplicadas a las RBMs. En NCE, como en este trabajo, se emplea un criterio de entrenamiento discriminativo para ajustar un modelo generativo. Sin embargo, en lugar de ajustar un modelo discriminativo separado, el propio modelo generativo se utiliza para discriminar los datos generados de las muestras de una distribución de ruido fija. Debido a que NCE usa una distribución de ruido fija, el aprendizaje se ralentiza drásticamente después de que el modelo ha aprendido incluso una distribución aproximadamente correcta sobre un pequeño subconjunto de las variables observadas.

Finalmente, algunas técnicas no implican definir explícitamente una distribución de probabilidad, sino que entrenan una máquina generativa para extraer muestras de la distribución deseada. Este enfoque tiene la ventaja de que tales máquinas pueden diseñarse para ser entrenadas mediante retropropagación. El trabajo reciente más destacado en esta área incluye el marco de redes estocásticas generativas (GSN) [5], que extiende los autoencoders de denoising generalizados [4]: ambos pueden verse como definiciones de una cadena de Markov parametrizada, es decir, uno aprende los parámetros de una máquina que realiza un paso de una cadena de Markov generativa. En comparación con las GSNs, el marco de redes adversariales no requiere una cadena de Markov para el muestreo. Debido a que las redes adversariales no requieren bucles de retroalimentación durante la generación, son mejor capaces de aprovechar las unidades lineales por partes [19, 9, 10], que mejoran el rendimiento de la retropropagación pero tienen problemas con la activación ilimitada cuando se usan en un bucle de retroalimentación. Ejemplos más recientes de entrenamiento de una máquina generativa mediante retropropagación incluyen el trabajo reciente sobre la variación autoencodificadora Bayesiana [20] y la retropropagación estocástica [24].

## 3 Redes Adversariales

El marco de modelado adversarial es más sencillo de aplicar cuando ambos modelos son perceptrones multicapa. Para aprender la distribución \( p_g \) del generador sobre los datos \( x \), definimos una distribución previa en las variables de ruido de entrada \( p_z(z) \), luego representamos un mapeo al espacio de datos como \( G(z; \theta_g) \), donde \( G \) es una función diferenciable representada por un perceptrón multicapa con parámetros \( \theta_g \). También definimos un segundo perceptrón multicapa \( D(x; \theta_d) \) que produce un único escalar. \( D(x) \) representa la probabilidad de que \( x \) provenga de los datos en lugar de \( p_g \). Entrenamos \( D \) para maximizar la probabilidad de asignar la etiqueta correcta tanto a los ejemplos de entrenamiento como a las muestras de \( G \). Simultáneamente entrenamos \( G \) para minimizar \( \log(1 - D(G(z))) \):

En otras palabras, D y G juegan el siguiente juego minimax de dos jugadores con la función de valor V(G, D):

\[ 
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)} \left[ \log D(x) \right] + \mathbb{E}_{z \sim p_z(z)} \left[ \log(1 - D(G(z))) \right]. \quad (1)
\]


En la siguiente sección, presentamos un análisis teórico de las redes adversariales, mostrando esencialmente que el criterio de entrenamiento permite recuperar la distribución generadora de datos a medida que \( G \) y \( D \) tienen suficiente capacidad, es decir, en el límite no paramétrico. Véase la Figura 1 para una explicación menos formal y más pedagógica del enfoque. En la práctica, debemos implementar el juego usando un enfoque numérico iterativo. Optimi
